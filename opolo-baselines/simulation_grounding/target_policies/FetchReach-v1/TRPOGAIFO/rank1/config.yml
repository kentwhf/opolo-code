actor_lr: 0.001
batch_size: 256
buffer_size: 1000000
critic_lr: 0.001
gamma: 0.95
goal_selection_strategy: future
model_class: ddpg
n_sampled_goal: 4
n_timesteps: 20000.0
noise_std: 0.2
noise_type: normal
normalize_observations: true
normalize_returns: false
policy: MlpPolicy
policy_kwargs: dict(layers=[256, 256, 256])
random_exploration: 0.3
